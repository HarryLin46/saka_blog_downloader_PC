{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\lib\\site-packages (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from beautifulsoup4) (1.8)\n",
      "Requirement already satisfied: pip in c:\\users\\user\\anaconda3\\lib\\site-packages (22.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,bs4,os,json,time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.nogizaka46.com/s/n46/diary/MEMBER/list?ima=0107&ct=48006/s/n46/diary/detail/100509?ima=2301&cd=MEMBER'\n",
    "# html = requests.get(url)\n",
    "# print('網頁下載中')\n",
    "# html.raise_for_status()\n",
    "# print('網頁下載成功')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create Nogizaka46 directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deskDir = 'Nogizaka46'\n",
    "if os.path.exists(deskDir) == False:\n",
    "    os.mkdir(deskDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['秋元 真夏', '伊藤 理々杏', '岩本 蓮加', '梅澤 美波', '遠藤 さくら', '賀喜 遥香', '掛橋 沙耶香', '金川 紗耶', '北川 悠理', '久保 史緒里', '黒見明香', '齋藤 飛鳥', '阪口 珠美', '佐藤 楓', '佐藤璃果', '柴田 柚菜', '鈴木 絢音', '清宮 レイ', '田村 真佑', '筒井 あやめ', '中村 麗乃', '早川 聖来', '林瑠奈', '樋口 日奈', '松尾美佑', '向井 葉月', '矢久保 美緒', '山崎 怜奈', '山下 美月', '弓木奈於', '吉田 綾乃クリスティー', '与田 祐希', '和田 まあや', '5期生リレー']\n"
     ]
    }
   ],
   "source": [
    "fn = 'member_list.json'\n",
    "\n",
    "with open(fn,'r',encoding='utf-8') as fnobj:\n",
    "    member_list = json.load(fnobj)\n",
    "print(member_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(member_list)):\n",
    "#     folderpath = './Nogizaka46' + '/' + member_list[i]\n",
    "#     if os.path.isdir(folderpath) == False:\n",
    "#         path = os.path.join('./Nogizaka46', member_list[i]) \n",
    "#         os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find blog links on current page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "# blogData = main_objSoup.find_all('a',class_='bl--card js-pos a--op hv--thumb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(blogData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(bloglinks)):\n",
    "#     print(bloglinks[i]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(url[0:26]+bloglinks[0]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(blogData[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_page(current_objSoup):\n",
    "    global current_page,download_complete\n",
    "    \n",
    "    nextPages = current_objSoup.find_all('ul',class_ = \"pager\")\n",
    "    nextpage = nextPages[0].find_all('li',class_ = 'coun')\n",
    "#     print(len(nextpage))\n",
    "#     if current_page == 3:\n",
    "#         download_complete = True\n",
    "#         return ''\n",
    "    for i in range(len(nextpage)):\n",
    "        if nextpage[i].text == str(current_page+1):\n",
    "            current_page += 1\n",
    "            targetpage = nextpage[i]\n",
    "            link = targetpage.find('a')['href']\n",
    "            return url[:26] + link\n",
    "    #it is end\n",
    "    download_complete = True\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def download_pictures(blog_url,blog_index):\n",
    "    global current_new,download_complete,current_page\n",
    "    #url = https://www.nogizaka46.com/s/n46/diary/detail/100577?ima=2936&cd=MEMBER\n",
    "    html = requests.get(blog_url)\n",
    "    time.sleep(1)\n",
    "    objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "    \n",
    "    imgTag = objSoup.select('img')\n",
    "#     print(len(imgTag))\n",
    "    author_member = objSoup.find('p',class_ = 'bd--prof__name f--head').text\n",
    "    \n",
    "    blog_title = objSoup.find('h1', class_ = 'bd--hd__ttl f--head a--tx js-tdi').text\n",
    "    if blog_title is None:\n",
    "        blog_title = ''\n",
    "\n",
    "    dateTime = objSoup.find('p', class_ = \"bd--hd__date a--tx js-tdi\").text\n",
    "    date = dateTime[:10]\n",
    "    date = date.replace('.','')\n",
    "    \n",
    "    data = [dateTime,author_member,blog_title]\n",
    "        \n",
    "    if data == current_new: #we can stop here\n",
    "        download_complete = True\n",
    "    else:\n",
    "        #blog_title may not a good directory name\n",
    "        blog_title = blog_title[:150]\n",
    "        special_char = r'/\\:*?\"<>|'\n",
    "        for i in special_char:\n",
    "            blog_title = blog_title.replace(i,'')\n",
    "\n",
    "        dir_path_member = './Nogizaka46/' + author_member\n",
    "        \n",
    "        if author_member[-5:] == '期生リレー':\n",
    "            member = blog_title.split()[-1]\n",
    "            dir_path = './Nogizaka46/' + author_member + '/' + member\n",
    "            if os.path.exists(dir_path) == False:\n",
    "                os.mkdir(dir_path)\n",
    "                \n",
    "            dir_path = './Nogizaka46/' + author_member + '/' + member + '/' +date + ' ' + blog_title\n",
    "        else:\n",
    "            dir_path = './Nogizaka46/' + author_member + '/' + date + ' ' + blog_title\n",
    "\n",
    "        \n",
    "        #the space at the end of blog_title should be remove\n",
    "        dir_path = dir_path.rstrip(' .')\n",
    "        \n",
    "        if os.path.exists(dir_path_member) == False:\n",
    "            os.mkdir(dir_path_member)\n",
    "        if os.path.exists(dir_path) == False:\n",
    "            os.mkdir(dir_path)\n",
    "            if len(imgTag) > 0 :\n",
    "                for i in range(len(imgTag)):\n",
    "                    imgUrl = imgTag[i].get('src')\n",
    "\n",
    "                    try:\n",
    "                        is_effective_url = (not imgUrl is None) and ((imgUrl[-4:] in ['.jpg','.tif','.png']) or (imgUrl[-5:] in ['.jpeg']))\n",
    "                        if is_effective_url: #we may catch something we don't want(no 'src') \n",
    "                            finUrl = url[:26] + imgUrl\n",
    "                            \n",
    "                            picture = requests.get(finUrl)\n",
    "                            time.sleep(0.5)\n",
    "                            picture.raise_for_status()\n",
    "            #                 print('%s 圖片下載成功' %finUrl)\n",
    "\n",
    "                            pictFile = open(os.path.join(dir_path,os.path.basename(imgUrl)),'wb')\n",
    "                            for diskStorage in picture.iter_content(1024*1024):\n",
    "                                pictFile.write(diskStorage)\n",
    "                            pictFile.close()\n",
    "                    except requests.exceptions.HTTPError:\n",
    "                        print(current_page,blog_index+1,'找不到網頁! 照片可能被鎖了',author_member,blog_title)\n",
    "                        \n",
    "                    except:\n",
    "                        print(current_page,blog_index+1,'新的未知錯誤出現! 可能是異常個案',author_member,blog_title)\n",
    "        else:\n",
    "            print('看到重複的部落格了')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_current_new(current_new_url):\n",
    "    html = requests.get(current_new_url)\n",
    "    time.sleep(1)\n",
    "    objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "    \n",
    "    author_member = objSoup.find('p',class_ = 'bd--prof__name f--head').text\n",
    "    blog_title = objSoup.find('h1', class_ = 'bd--hd__ttl f--head a--tx js-tdi').text\n",
    "    if blog_title is None:\n",
    "        blog_title = ''\n",
    "    dateTime = objSoup.find('p', class_ = \"bd--hd__date a--tx js-tdi\").text\n",
    "    \n",
    "    current_new_data = [dateTime,author_member,blog_title]\n",
    "    \n",
    "    fn = 'current_new.json'\n",
    "    with open(fn,'w',encoding='utf-8') as obj:\n",
    "        json.dump(current_new_data,obj,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_blogs(current_objSoup):\n",
    "    global current_new,current_page,download_complete\n",
    "    blogData = current_objSoup.find_all('a',class_='bl--card js-pos a--op hv--thumb')\n",
    "    \n",
    "    for i in range(len(blogData)):\n",
    "        link = blogData[i]['href']\n",
    "        blog_url = url[:26] + link\n",
    "        \n",
    "        if not download_complete:\n",
    "            download_pictures(blog_url,i)\n",
    "        \n",
    "        if current_page == 1 and i == 0: #always update first\n",
    "            update_current_new(blog_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_page = 1\n",
    "current_url = url\n",
    "\n",
    "download_complete = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get current new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'current_new.json'\n",
    "\n",
    "try:\n",
    "    with open(fn,'r',encoding='utf-8') as fnobj:\n",
    "        current_new = json.load(fnobj)\n",
    "\n",
    "except Exception: #the 1st run of this code\n",
    "    current_new = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "while not download_complete:\n",
    "    print(current_page)\n",
    "    html = requests.get(current_url)\n",
    "    current_objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "    try:\n",
    "        download_blogs(current_objSoup)\n",
    "    except FileExistsError as e:\n",
    "        print('檔案已存在! 載到重複的部落格')\n",
    "        break\n",
    "    except FileNotFoundError as e:\n",
    "        print('檔案找不到! 可能部落格名稱太長或路徑有錯')\n",
    "        break\n",
    "    except NotADirectoryError as e:\n",
    "        print('目錄名稱無效! 可能資料夾命名不合法')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print( e,'可能為異常個案')\n",
    "    current_url = get_next_page(current_objSoup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(2) ==int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(elem.isdigit() for elem in '25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '5期生リレー'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'期生リレー'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-676612e37450>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "a - a[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-af7ae56c2f81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m'24'\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;34m'4'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "'24'/'4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = '20220506 さ〜つきちゃ〜ん！　菅原咲月'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'菅原咲月'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
