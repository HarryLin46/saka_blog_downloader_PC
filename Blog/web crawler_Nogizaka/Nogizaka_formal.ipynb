{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbca25b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\autum\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\autum\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: pip in c:\\users\\autum\\anaconda3\\lib\\site-packages (23.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a26c4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,bs4,os,json,time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21271b12",
   "metadata": {},
   "source": [
    "## download html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1650a478",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.nogizaka46.com/s/n46/diary/MEMBER/list?ima=0107&ct=48006/s/n46/diary/detail/100509?ima=2301&cd=MEMBER'\n",
    "# html = requests.get(url)\n",
    "# print('網頁下載中')\n",
    "# html.raise_for_status()\n",
    "# print('網頁下載成功')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72503ad1",
   "metadata": {},
   "source": [
    "## create Nogizaka46 directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e7e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deskDir = 'Nogizaka46'\n",
    "if os.path.exists(deskDir) == False:\n",
    "    os.mkdir(deskDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68067ae6",
   "metadata": {},
   "source": [
    "## create member list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0411f9fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['秋元真夏', '伊藤理々杏', '岩本蓮加', '梅澤美波', '遠藤さくら', '賀喜遥香', '掛橋沙耶香', '金川紗耶', '北川悠理', '久保史緒里', '黒見明香', '齋藤飛鳥', '阪口珠美', '佐藤楓', '佐藤璃果', '柴田柚菜', '鈴木絢音', '清宮レイ', '田村真佑', '筒井あやめ', '中村麗乃', '早川聖来', '林瑠奈', '樋口日奈', '松尾美佑', '向井 葉月', '矢久保美緒', '山崎怜奈', '山下美月', '弓木奈於', '吉田綾乃クリスティー', '与田祐希', '和田まあや', '五百城茉央', '池田瑛紗', '一ノ瀬美空', '井上和', '岡本姫奈', '小川彩', '奥田いろは', '川﨑桜', '菅原咲月', '冨里奈央', '中西アルノ']\n"
     ]
    }
   ],
   "source": [
    "fn = 'member_list.json'\n",
    "\n",
    "with open(fn,'r',encoding='utf-8') as fnobj:\n",
    "    member_list = json.load(fnobj)\n",
    "print(member_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc367b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(member_list)):\n",
    "#     folderpath = './Nogizaka46' + '/' + member_list[i]\n",
    "#     if os.path.isdir(folderpath) == False:\n",
    "#         path = os.path.join('./Nogizaka46', member_list[i]) \n",
    "#         os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb78b4",
   "metadata": {},
   "source": [
    "## find blog links on current page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2347fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "# blogData = main_objSoup.find_all('a',class_='bl--card js-pos a--op hv--thumb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f6af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(blogData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7131aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(bloglinks)):\n",
    "#     print(bloglinks[i]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6795fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(url[0:26]+bloglinks[0]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "117013ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(blogData[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff9f1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_page(current_objSoup):\n",
    "    global current_page,download_complete\n",
    "    \n",
    "    nextPages = current_objSoup.find_all('ul',class_ = \"pager\")\n",
    "    nextpage = nextPages[0].find_all('li',class_ = 'coun')\n",
    "#     print(len(nextpage))\n",
    "#     if current_page == 3:\n",
    "#         download_complete = True\n",
    "#         return ''\n",
    "    for i in range(len(nextpage)):\n",
    "        if nextpage[i].text == str(current_page+1):\n",
    "            current_page += 1\n",
    "            targetpage = nextpage[i]\n",
    "            link = targetpage.find('a')['href']\n",
    "            return url[:26] + link\n",
    "    #it is end\n",
    "    download_complete = True\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dbd0524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def download_pictures(blog_url,blog_index):\n",
    "    global current_new,download_complete,current_page,member_list,author_member\n",
    "    #url = https://www.nogizaka46.com/s/n46/diary/detail/100577?ima=2936&cd=MEMBER\n",
    "    html = requests.get(blog_url)\n",
    "    time.sleep(1)\n",
    "    objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "    \n",
    "    imgTag = objSoup.select('img')\n",
    "#     print(len(imgTag))\n",
    "    author_member = objSoup.find('p',class_ = 'bd--prof__name f--head').text\n",
    "    \n",
    "    blog_title = objSoup.find('h1', class_ = 'bd--hd__ttl f--head a--tx js-tdi').text\n",
    "    if blog_title is None:\n",
    "        blog_title = ''\n",
    "\n",
    "    dateTime = objSoup.find('p', class_ = \"bd--hd__date a--tx js-tdi\").text\n",
    "    date = dateTime[:10]\n",
    "    date = date.replace('.','')\n",
    "    \n",
    "    data = [dateTime,author_member,blog_title]\n",
    "        \n",
    "    if data == current_new: #we can stop here\n",
    "        download_complete = True\n",
    "    else:\n",
    "        #blog_title may not a good directory name\n",
    "        blog_title = blog_title[:150]\n",
    "        special_char = r'/\\:*?\"<>|'\n",
    "        for i in special_char:\n",
    "            blog_title = blog_title.replace(i,'')\n",
    "\n",
    "        dir_path_member = './Nogizaka46/' + author_member\n",
    "        \n",
    "        if author_member[-5:] == '期生リレー':\n",
    "            member = blog_title.split()[-1]\n",
    "            if not member in member_list:\n",
    "                member = ''.join(blog_title.split()[-2:])\n",
    "                if not member in member_list:\n",
    "                    print('成員名字找錯')\n",
    "            dir_path = './Nogizaka46/' + author_member + '/' + member\n",
    "            if os.path.exists(dir_path) == False:\n",
    "                os.mkdir(dir_path)\n",
    "                \n",
    "            dir_path = './Nogizaka46/' + author_member + '/' + member + '/' + date + ' ' + blog_title\n",
    "        else:\n",
    "            dir_path = './Nogizaka46/' + author_member + '/' + date + ' ' + blog_title\n",
    "\n",
    "        \n",
    "        #the space at the end of blog_title should be remove\n",
    "        dir_path = dir_path.rstrip(' .')\n",
    "        \n",
    "        if os.path.exists(dir_path_member) == False:\n",
    "            os.mkdir(dir_path_member)\n",
    "        if os.path.exists(dir_path) == False:\n",
    "            os.mkdir(dir_path)\n",
    "            if len(imgTag) > 0 :\n",
    "                for i in range(len(imgTag)):\n",
    "                    imgUrl = imgTag[i].get('src')\n",
    "\n",
    "                    try:\n",
    "                        is_effective_url = (not imgUrl is None) and ((imgUrl[-4:] in ['.jpg','.tif','.png']) or (imgUrl[-5:] in ['.jpeg']))\n",
    "                        if is_effective_url: #we may catch something we don't want(no 'src') \n",
    "                            finUrl = url[:26] + imgUrl\n",
    "                            \n",
    "                            picture = requests.get(finUrl)\n",
    "                            time.sleep(0.5)\n",
    "                            picture.raise_for_status()\n",
    "            #                 print('%s 圖片下載成功' %finUrl)\n",
    "\n",
    "                            pictFile = open(os.path.join(dir_path,str(i).zfill(2) + (imgUrl[-4:] if imgUrl[-4:] in ['.jpg','.tif','.png'] else imgUrl[-5:])),'wb')\n",
    "                            for diskStorage in picture.iter_content(1024*1024):\n",
    "                                pictFile.write(diskStorage)\n",
    "                            pictFile.close()\n",
    "                    except requests.exceptions.HTTPError:\n",
    "                        print(current_page,blog_index+1,'找不到網頁! 照片可能被鎖了',author_member,blog_title)\n",
    "                        \n",
    "                    except:\n",
    "                        print(current_page,blog_index+1,'新的未知錯誤出現! 可能是異常個案',author_member,blog_title)\n",
    "        else:\n",
    "            print('看到重複的部落格了')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac7ee081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_current_new(current_new_url):\n",
    "    html = requests.get(current_new_url)\n",
    "    time.sleep(1)\n",
    "    objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "    \n",
    "    author_member = objSoup.find('p',class_ = 'bd--prof__name f--head').text\n",
    "    blog_title = objSoup.find('h1', class_ = 'bd--hd__ttl f--head a--tx js-tdi').text\n",
    "    if blog_title is None:\n",
    "        blog_title = ''\n",
    "    dateTime = objSoup.find('p', class_ = \"bd--hd__date a--tx js-tdi\").text\n",
    "    \n",
    "    current_new_data = [dateTime,author_member,blog_title]\n",
    "    \n",
    "    fn = 'current_new.json'\n",
    "    with open(fn,'w',encoding='utf-8') as obj:\n",
    "        json.dump(current_new_data,obj,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9310aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_blogs(current_objSoup):\n",
    "    global current_new,current_page,download_complete\n",
    "    blogData = current_objSoup.find_all('a',class_='bl--card js-pos a--op hv--thumb')\n",
    "    \n",
    "    for i in range(len(blogData)):\n",
    "        link = blogData[i]['href']\n",
    "        blog_url = url[:26] + link\n",
    "        \n",
    "        if not download_complete:\n",
    "            download_pictures(blog_url,i)\n",
    "        \n",
    "        if current_page == 1 and i == 0: #always update first\n",
    "            update_current_new(blog_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fda06f",
   "metadata": {},
   "source": [
    "## set some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af47e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_page = 1\n",
    "current_url = url\n",
    "\n",
    "download_complete = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a3530",
   "metadata": {},
   "source": [
    "## get current new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "333429bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'current_new.json'\n",
    "\n",
    "try:\n",
    "    with open(fn,'r',encoding='utf-8') as fnobj:\n",
    "        current_new = json.load(fnobj)\n",
    "\n",
    "except Exception: #the 1st run of this code\n",
    "    current_new = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4948a1d",
   "metadata": {},
   "source": [
    "## main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "932605c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "while not download_complete:\n",
    "    print(current_page)\n",
    "    html = requests.get(current_url)\n",
    "    current_objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "    try:\n",
    "        download_blogs(current_objSoup)\n",
    "    except FileExistsError as e:\n",
    "        print('檔案已存在! 載到重複的部落格')\n",
    "        break\n",
    "    except FileNotFoundError as e:\n",
    "        print('檔案找不到! 可能部落格名稱太長或路徑有錯')\n",
    "        break\n",
    "    except NotADirectoryError as e:\n",
    "        print('目錄名稱無效! 可能資料夾命名不合法')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print( e,'可能為異常個案')\n",
    "    current_url = get_next_page(current_objSoup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
