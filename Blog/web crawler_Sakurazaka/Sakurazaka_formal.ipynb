{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1fbab3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\autum\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\autum\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: pip in c:\\users\\autum\\anaconda3\\lib\\site-packages (23.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27e0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,bs4,os,json,time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eea26e",
   "metadata": {},
   "source": [
    "**fill in the member whose blog you want to download here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7942cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_member_list = [\n",
    "    [\"current_new_森田 ひかる.json\",'https://sakurazaka46.com/s/s46/diary/blog/list?ima=0000&ct=50'],\n",
    "    ['current_new_大園 玲.json',\"https://sakurazaka46.com/s/s46/diary/blog/list?ima=2951&ct=54\"],\n",
    "    ['current_new_三期生リレー.json','https://sakurazaka46.com/s/s46/diary/blog/list?ima=0000&ct=2000']\n",
    "    \n",
    "     \n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ca3c0",
   "metadata": {},
   "source": [
    "## download html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c52920",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://sakurazaka46.com/s/s46/diary/blog/list?ima=4714&page=0&ct=50&cd=blog'\n",
    "html = requests.get(url)\n",
    "time.sleep(1)\n",
    "objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "# html = requests.get(url)\n",
    "# print('網頁下載中')\n",
    "# html.raise_for_status()\n",
    "# print('網頁下載成功')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b739f05e",
   "metadata": {},
   "source": [
    "## create Sakurazaka46 directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad55603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deskDir = 'Sakurazaka46'\n",
    "if os.path.exists(deskDir) == False:\n",
    "    os.mkdir(deskDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234dd7c9",
   "metadata": {},
   "source": [
    "## find blog links on current page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df394db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_page(current_objSoup):\n",
    "    global current_page,download_complete\n",
    "    \n",
    "    box = current_objSoup.find('div', class_ = \"com-pager wid1200\")\n",
    "    nextpage = box.find_all('li')\n",
    "    for i in range(len(nextpage)):\n",
    "        if nextpage[i].text == str(current_page+1):\n",
    "            current_page += 1\n",
    "            targetpage = nextpage[i]\n",
    "            link = targetpage.find('a')['href']\n",
    "            return url[:24] + link\n",
    "    #it is end\n",
    "    download_complete = True\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac12914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def download_pictures(blog_url,blog_index):\n",
    "    global current_new,download_complete\n",
    "    #url = https://www.nogizaka46.com/s/n46/diary/detail/100577?ima=2936&cd=MEMBER\n",
    "    html = requests.get(blog_url)\n",
    "    time.sleep(1)\n",
    "    objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "    \n",
    "    box = objSoup.find('div',class_ = \"box-article\")\n",
    "    imgTag = box.find_all('img')\n",
    "    \n",
    "    author_member = objSoup.find('p', class_ = \"name\").text\n",
    "    \n",
    "    blog_title = objSoup.find('h1', class_ = \"title\").text\n",
    "    \n",
    "    dateTime_raw = objSoup.find_all('p', class_ = \"date wf-a\")\n",
    "    dateTime = dateTime_raw[1].text.split('/')\n",
    "    date = dateTime[0] + dateTime[1] + dateTime[2][:2]\n",
    "    \n",
    "    \n",
    "    data = [dateTime,author_member,blog_title]\n",
    "    if data == current_new: #we can stop here\n",
    "        download_complete = True\n",
    "    else:\n",
    "        #blog_title may not a good directory name\n",
    "        blog_title = blog_title[:150]\n",
    "        special_char = r'/\\:*?\"<>|'\n",
    "        for i in special_char:\n",
    "            blog_title = blog_title.replace(i,'')\n",
    "\n",
    "        dir_path_member = './Sakurazaka46/' + author_member\n",
    "        dir_path = './Sakurazaka46/' + author_member + '/' + date + ' ' + blog_title\n",
    "        \n",
    "        #the space at the end of blog_title should be remove\n",
    "        dir_path = dir_path.rstrip(' .')\n",
    "        \n",
    "        if os.path.exists(dir_path_member) == False:\n",
    "            os.mkdir(dir_path_member)\n",
    "        if os.path.exists(dir_path) == False:\n",
    "            os.mkdir(dir_path)\n",
    "            if len(imgTag) > 0 :\n",
    "                for i in range(len(imgTag)):\n",
    "                    imgUrl = imgTag[i].get('src')\n",
    "\n",
    "                    try:\n",
    "                        is_effective_url = (not imgUrl is None) and ((imgUrl[-4:] in ['.jpg','.tif','.png']) or (imgUrl[-5:] in ['.jpeg']))\n",
    "                        if is_effective_url: #we may catch something we don't want(no 'src') \n",
    "                            finUrl = url[:24] + imgUrl\n",
    "                            \n",
    "                            picture = requests.get(finUrl)\n",
    "                            time.sleep(0.5)\n",
    "                            picture.raise_for_status()\n",
    "            #                 print('%s 圖片下載成功' %finUrl)\n",
    "\n",
    "                            pictFile = open(os.path.join(dir_path,str(i).zfill(2) + (imgUrl[-4:] if imgUrl[-4:] in ['.jpg','.tif','.png'] else imgUrl[-5:])),'wb')\n",
    "                            for diskStorage in picture.iter_content(1024*1024):\n",
    "                                pictFile.write(diskStorage)\n",
    "                            pictFile.close()\n",
    "                    except requests.exceptions.HTTPError:\n",
    "                        print(current_page,blog_index+1,'找不到網頁! 照片可能被鎖了',author_member,blog_title)\n",
    "                        \n",
    "                    except:\n",
    "                        print(current_page,blog_index+1,'新的未知錯誤出現! 可能是異常個案',author_member,blog_title)\n",
    "        else:\n",
    "            print('看到重複的部落格了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a0cc6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_current_new(current_new_url):\n",
    "    html = requests.get(current_new_url)\n",
    "    time.sleep(1)\n",
    "    objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "    \n",
    "    blog_tags = objSoup.find_all('div', class_ = \"c-blog-article__text\")\n",
    "    \n",
    "    author_member = objSoup.find('p', class_ = \"name\").text\n",
    "    \n",
    "    blog_title = objSoup.find('h1', class_ = \"title\").text\n",
    "    \n",
    "    dateTime_raw = objSoup.find_all('p', class_ = \"date wf-a\")\n",
    "    dateTime = dateTime_raw[1].text.split('/')\n",
    "    date = dateTime[0] + dateTime[1] + dateTime[2][:2]\n",
    "    \n",
    "    current_new_data = [dateTime,author_member,blog_title]\n",
    "    \n",
    "    fn = 'current_new_' + author_member +'.json'\n",
    "    with open(fn,'w',encoding='utf-8') as obj:\n",
    "        json.dump(current_new_data,obj,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "828f13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_blogs(current_objSoup):\n",
    "    global current_new,current_page,download_complete\n",
    "    boxes_raw = current_objSoup.find_all('li',class_ = 'box')\n",
    "    boxes = []\n",
    "    for i in boxes_raw:\n",
    "        if i.find('div',class_ =  'wrap-bg') is not None:\n",
    "            boxes.append(i)\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        link = boxes[i].find('a')['href']\n",
    "        blog_url = url[:24] + link\n",
    "        \n",
    "        if not download_complete:\n",
    "            download_pictures(blog_url,i)\n",
    "        \n",
    "        if current_page == 1 and i == 0: #always update first\n",
    "            update_current_new(blog_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d483583",
   "metadata": {},
   "source": [
    "**define main loop function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b88a81f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_main_loop_for_desired_member(current_new_title,member_url):\n",
    "    global current_new,current_page,download_complete\n",
    "    fn = current_new_title\n",
    "\n",
    "    try:\n",
    "        with open(fn,'r',encoding='utf-8') as fnobj:\n",
    "            current_new = json.load(fnobj)\n",
    "\n",
    "    except Exception: #the 1st run of this code\n",
    "        current_new = ''\n",
    "        \n",
    "    current_page = 1\n",
    "    current_url = member_url\n",
    "\n",
    "    download_complete = False\n",
    "    while not download_complete:\n",
    "        print(current_page)\n",
    "        html = requests.get(current_url)\n",
    "        current_objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "        try:\n",
    "            download_blogs(current_objSoup)\n",
    "        except FileExistsError as e:\n",
    "            print('檔案已存在! 載到重複的部落格')\n",
    "            break\n",
    "        except FileNotFoundError as e:\n",
    "            print('檔案找不到! 可能部落格名稱太長或路徑有錯')\n",
    "            break\n",
    "        except NotADirectoryError as e:\n",
    "            print('目錄名稱無效! 可能資料夾命名不合法')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print( e,'可能為異常個案')\n",
    "        current_url = get_next_page(current_objSoup)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2086170",
   "metadata": {},
   "source": [
    "****Run****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51febbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_new_森田 ひかる.json\n",
      "1\n",
      "current_new_大園 玲.json\n",
      "1\n",
      "current_new_三期生リレー.json\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for member in desired_member_list:\n",
    "    print(member[0])\n",
    "    run_main_loop_for_desired_member(member[0],member[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c77f7b1",
   "metadata": {},
   "source": [
    "## get current new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7d1e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn = 'current_new_森田 ひかる.json'\n",
    "#\n",
    "#try:\n",
    "#    with open(fn,'r',encoding='utf-8') as fnobj:\n",
    "#        current_new = json.load(fnobj)\n",
    "#\n",
    "#except Exception: #the 1st run of this code\n",
    "#    current_new = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2253ba",
   "metadata": {},
   "source": [
    "## main loop 森田 ひかる part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df533204",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#current_page = 1\n",
    "#current_url = 'https://sakurazaka46.com/s/s46/diary/blog/list?ima=4714&page=0&ct=50&cd=blog'\n",
    "#download_complete = False\n",
    "#while not download_complete:\n",
    "#    print(current_page)\n",
    "#    html = requests.get(current_url)\n",
    "#    current_objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "#    try:\n",
    "#        download_blogs(current_objSoup)\n",
    "#    except FileExistsError as e:\n",
    "#        print('檔案已存在! 載到重複的部落格')\n",
    "#        break\n",
    "#    except FileNotFoundError as e:\n",
    "#        print('檔案找不到! 可能部落格名稱太長或路徑有錯')\n",
    "#        break\n",
    "#    except NotADirectoryError as e:\n",
    "#        print('目錄名稱無效! 可能資料夾命名不合法')\n",
    "#        break\n",
    "#    except Exception as e:\n",
    "#        print( e,'可能為異常個案')\n",
    "#    current_url = get_next_page(current_objSoup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d128a13",
   "metadata": {},
   "source": [
    "## get current new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf8e6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn = 'current_new_大園 玲.json'\n",
    "#\n",
    "#try:\n",
    "#    with open(fn,'r',encoding='utf-8') as fnobj:\n",
    "#        current_new = json.load(fnobj)\n",
    "#\n",
    "#except Exception: #the 1st run of this code\n",
    "#    current_new = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf17d4f",
   "metadata": {},
   "source": [
    "## main loop 大園 玲 part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f9f1e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_page = 1\n",
    "#current_url = 'https://sakurazaka46.com/s/s46/diary/blog/list?ima=2951&ct=54'\n",
    "#\n",
    "#download_complete = False\n",
    "#while not download_complete:\n",
    "#    print(current_page)\n",
    "#    html = requests.get(current_url)\n",
    "#    current_objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "#    try:\n",
    "#        download_blogs(current_objSoup)\n",
    "#    except FileExistsError as e:\n",
    "#        print('檔案已存在! 載到重複的部落格')\n",
    "#        break\n",
    "#    except FileNotFoundError as e:\n",
    "#        print('檔案找不到! 可能部落格名稱太長或路徑有錯')\n",
    "#        break\n",
    "#    except NotADirectoryError as e:\n",
    "#        print('目錄名稱無效! 可能資料夾命名不合法')\n",
    "#        break\n",
    "#    except Exception as e:\n",
    "#        print( e,'可能為異常個案')\n",
    "#    current_url = get_next_page(current_objSoup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7945048",
   "metadata": {},
   "source": [
    "**三期生relay**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23339c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'current_new_三期生リレー.json'\n",
    "\n",
    "try:\n",
    "    with open(fn,'r',encoding='utf-8') as fnobj:\n",
    "        current_new = json.load(fnobj)\n",
    "\n",
    "except Exception: #the 1st run of this code\n",
    "    current_new = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1e3ed64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "current_page = 1\n",
    "current_url = 'https://sakurazaka46.com/s/s46/diary/blog/list?ima=0000&ct=2000'\n",
    "\n",
    "download_complete = False\n",
    "while not download_complete:\n",
    "    print(current_page)\n",
    "    html = requests.get(current_url)\n",
    "    current_objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "    try:\n",
    "        download_blogs(current_objSoup)\n",
    "    except FileExistsError as e:\n",
    "        print('檔案已存在! 載到重複的部落格')\n",
    "        break\n",
    "    except FileNotFoundError as e:\n",
    "        print('檔案找不到! 可能部落格名稱太長或路徑有錯')\n",
    "        break\n",
    "    except NotADirectoryError as e:\n",
    "        print('目錄名稱無效! 可能資料夾命名不合法')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print( e,'可能為異常個案')\n",
    "    current_url = get_next_page(current_objSoup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c763b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
