{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3b82705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\harry\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\harry\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.1)\n",
      "Requirement already satisfied: pip in c:\\users\\harry\\anaconda3\\lib\\site-packages (22.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb5576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,bs4,os,json,time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dabd5f",
   "metadata": {},
   "source": [
    "## download html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae0154bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://sakurazaka46.com/s/s46/diary/blog/list?ima=4714&page=0&ct=50&cd=blog'\n",
    "html = requests.get(url)\n",
    "time.sleep(1)\n",
    "objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "# html = requests.get(url)\n",
    "# print('網頁下載中')\n",
    "# html.raise_for_status()\n",
    "# print('網頁下載成功')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455ce72",
   "metadata": {},
   "source": [
    "## create Sakurazaka46 directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58682855",
   "metadata": {},
   "outputs": [],
   "source": [
    "deskDir = 'Sakurazaka46'\n",
    "if os.path.exists(deskDir) == False:\n",
    "    os.mkdir(deskDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b7705",
   "metadata": {},
   "source": [
    "## find blog links on current page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "403db7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_page(current_objSoup):\n",
    "    global current_page,download_complete\n",
    "    \n",
    "    box = current_objSoup.find('div', class_ = \"com-pager wid1200\")\n",
    "    nextpage = box.find_all('li')\n",
    "    for i in range(len(nextpage)):\n",
    "        if nextpage[i].text == str(current_page+1):\n",
    "            current_page += 1\n",
    "            targetpage = nextpage[i]\n",
    "            link = targetpage.find('a')['href']\n",
    "            return url[:24] + link\n",
    "    #it is end\n",
    "    download_complete = True\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13e90ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def download_pictures(blog_url,blog_index):\n",
    "    global current_new,download_complete\n",
    "    #url = https://www.nogizaka46.com/s/n46/diary/detail/100577?ima=2936&cd=MEMBER\n",
    "    html = requests.get(blog_url)\n",
    "    time.sleep(1)\n",
    "    objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "    \n",
    "    box = objSoup.find('div',class_ = \"box-article\")\n",
    "    imgTag = box.find_all('img')\n",
    "    \n",
    "    author_member = objSoup.find('p', class_ = \"name\").text\n",
    "    \n",
    "    blog_title = objSoup.find('h1', class_ = \"title\").text\n",
    "    \n",
    "    dateTime_raw = objSoup.find_all('p', class_ = \"date wf-a\")\n",
    "    dateTime = dateTime_raw[1].text.split('/')\n",
    "    date = dateTime[0] + dateTime[1] + dateTime[2][:2]\n",
    "    \n",
    "    \n",
    "    data = [dateTime_raw,author_member,blog_title]\n",
    "    if data == current_new: #we can stop here\n",
    "        download_complete = True\n",
    "    else:\n",
    "        #blog_title may not a good directory name\n",
    "        blog_title = blog_title[:150]\n",
    "        special_char = r'/\\:*?\"<>|'\n",
    "        for i in special_char:\n",
    "            blog_title = blog_title.replace(i,'')\n",
    "\n",
    "        dir_path_member = './Sakurazaka46/' + author_member\n",
    "        dir_path = './Sakurazaka46/' + author_member + '/' + date + ' ' + blog_title\n",
    "        \n",
    "        #the space at the end of blog_title should be remove\n",
    "        dir_path = dir_path.rstrip(' .')\n",
    "        \n",
    "        if os.path.exists(dir_path_member) == False:\n",
    "            os.mkdir(dir_path_member)\n",
    "        if os.path.exists(dir_path) == False:\n",
    "            os.mkdir(dir_path)\n",
    "            if len(imgTag) > 0 :\n",
    "                for i in range(len(imgTag)):\n",
    "                    imgUrl = imgTag[i].get('src')\n",
    "\n",
    "                    try:\n",
    "                        is_effective_url = (not imgUrl is None) and ((imgUrl[-4:] in ['.jpg','.tif','.png']) or (imgUrl[-5:] in ['.jpeg']))\n",
    "                        if is_effective_url: #we may catch something we don't want(no 'src') \n",
    "                            finUrl = url[:24] + imgUrl\n",
    "                            \n",
    "                            picture = requests.get(finUrl)\n",
    "                            time.sleep(0.5)\n",
    "                            picture.raise_for_status()\n",
    "            #                 print('%s 圖片下載成功' %finUrl)\n",
    "\n",
    "                            pictFile = open(os.path.join(dir_path,str(i).zfill(2) + (imgUrl[-4:] if imgUrl[-4:] in ['.jpg','.tif','.png'] else imgUrl[-5:])),'wb')\n",
    "                            for diskStorage in picture.iter_content(1024*1024):\n",
    "                                pictFile.write(diskStorage)\n",
    "                            pictFile.close()\n",
    "                    except requests.exceptions.HTTPError:\n",
    "                        print(current_page,blog_index+1,'找不到網頁! 照片可能被鎖了',author_member,blog_title)\n",
    "                        \n",
    "                    except:\n",
    "                        print(current_page,blog_index+1,'新的未知錯誤出現! 可能是異常個案',author_member,blog_title)\n",
    "        else:\n",
    "            print('看到重複的部落格了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e76026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_current_new(current_new_url):\n",
    "    html = requests.get(current_new_url)\n",
    "    time.sleep(1)\n",
    "    objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "    \n",
    "    blog_tags = objSoup.find_all('div', class_ = \"c-blog-article__text\")\n",
    "    \n",
    "    author_member = objSoup.find('p', class_ = \"name\").text\n",
    "    \n",
    "    blog_title = objSoup.find('h1', class_ = \"title\").text\n",
    "    \n",
    "    dateTime_raw = objSoup.find_all('p', class_ = \"date wf-a\")\n",
    "    dateTime = dateTime_raw[1].text.split('/')\n",
    "    date = dateTime[0] + dateTime[1] + dateTime[2][:2]\n",
    "    \n",
    "    current_new_data = [dateTime,author_member,blog_title]\n",
    "    \n",
    "    fn = 'current_new_' + author_member +'.json'\n",
    "    with open(fn,'w',encoding='utf-8') as obj:\n",
    "        json.dump(current_new_data,obj,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12a734a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_blogs(current_objSoup):\n",
    "    global current_new,current_page,download_complete\n",
    "    boxes_raw = current_objSoup.find_all('li',class_ = 'box')\n",
    "    boxes = []\n",
    "    for i in boxes_raw:\n",
    "        if i.find('div',class_ =  'wrap-bg') is not None:\n",
    "            boxes.append(i)\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        link = boxes[i].find('a')['href']\n",
    "        blog_url = url[:24] + link\n",
    "        \n",
    "        if not download_complete:\n",
    "            download_pictures(blog_url,i)\n",
    "        \n",
    "        if current_page == 1 and i == 0: #always update first\n",
    "            update_current_new(blog_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7261c1a",
   "metadata": {},
   "source": [
    "## get current new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "829fa4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'current_new_森田 ひかる.json'\n",
    "\n",
    "try:\n",
    "    with open(fn,'r',encoding='utf-8') as fnobj:\n",
    "        current_new = json.load(fnobj)\n",
    "\n",
    "except Exception: #the 1st run of this code\n",
    "    current_new = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf2f572",
   "metadata": {},
   "source": [
    "## main loop 森田 ひかる part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c3544d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "current_page = 1\n",
    "current_url = 'https://sakurazaka46.com/s/s46/diary/blog/list?ima=4714&page=0&ct=50&cd=blog'\n",
    "\n",
    "download_complete = False\n",
    "while not download_complete:\n",
    "    print(current_page)\n",
    "    html = requests.get(current_url)\n",
    "    current_objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "    try:\n",
    "        download_blogs(current_objSoup)\n",
    "    except FileExistsError as e:\n",
    "        print('檔案已存在! 載到重複的部落格')\n",
    "        break\n",
    "    except FileNotFoundError as e:\n",
    "        print('檔案找不到! 可能部落格名稱太長或路徑有錯')\n",
    "        break\n",
    "    except NotADirectoryError as e:\n",
    "        print('目錄名稱無效! 可能資料夾命名不合法')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print( e,'可能為異常個案')\n",
    "    current_url = get_next_page(current_objSoup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e04d70",
   "metadata": {},
   "source": [
    "## get current new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a35ffe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'current_new_大園 玲.json'\n",
    "\n",
    "try:\n",
    "    with open(fn,'r',encoding='utf-8') as fnobj:\n",
    "        current_new = json.load(fnobj)\n",
    "\n",
    "except Exception: #the 1st run of this code\n",
    "    current_new = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b025c326",
   "metadata": {},
   "source": [
    "## main loop 大園 玲 part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9201a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "current_page = 1\n",
    "current_url = 'https://sakurazaka46.com/s/s46/diary/blog/list?ima=2951&ct=54'\n",
    "\n",
    "download_complete = False\n",
    "while not download_complete:\n",
    "    print(current_page)\n",
    "    html = requests.get(current_url)\n",
    "    current_objSoup = bs4.BeautifulSoup(html.text,'lxml')\n",
    "    try:\n",
    "        download_blogs(current_objSoup)\n",
    "    except FileExistsError as e:\n",
    "        print('檔案已存在! 載到重複的部落格')\n",
    "        break\n",
    "    except FileNotFoundError as e:\n",
    "        print('檔案找不到! 可能部落格名稱太長或路徑有錯')\n",
    "        break\n",
    "    except NotADirectoryError as e:\n",
    "        print('目錄名稱無效! 可能資料夾命名不合法')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print( e,'可能為異常個案')\n",
    "    current_url = get_next_page(current_objSoup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
